{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnupJoseph/automated-mapping-topography/blob/master/SIH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_I3SAEpCRs",
        "colab_type": "code",
        "outputId": "f57e0dcd-0341-4f2c-f733-732d699fc2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGZPUHeONmNI",
        "colab_type": "code",
        "outputId": "ffe04b79-2b41-4fdb-b506-866eed1faada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rm -r sentinelhub-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sentinelhub-py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cDzQKFsMKeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/sentinel-hub/eo-learn.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHc-qGjxV4ZY",
        "colab_type": "code",
        "outputId": "bf30bb6f-975f-4c3e-f513-93852b99cbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cd cotent\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'cotent'\n",
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddNdOtWxNeqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install eo-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiLpTiQfpqbV",
        "colab_type": "code",
        "outputId": "00c5b0c7-f7b0-4eb1-926e-196c6ed1e7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/sentinel-hub/sentinelhub-py.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentinelhub-py'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/207)\u001b[K\rremote: Counting objects:   1% (3/207)\u001b[K\rremote: Counting objects:   2% (5/207)\u001b[K\rremote: Counting objects:   3% (7/207)\u001b[K\rremote: Counting objects:   4% (9/207)\u001b[K\rremote: Counting objects:   5% (11/207)\u001b[K\rremote: Counting objects:   6% (13/207)\u001b[K\rremote: Counting objects:   7% (15/207)\u001b[K\rremote: Counting objects:   8% (17/207)\u001b[K\rremote: Counting objects:   9% (19/207)\u001b[K\rremote: Counting objects:  10% (21/207)\u001b[K\rremote: Counting objects:  11% (23/207)\u001b[K\rremote: Counting objects:  12% (25/207)\u001b[K\rremote: Counting objects:  13% (27/207)\u001b[K\rremote: Counting objects:  14% (29/207)\u001b[K\rremote: Counting objects:  15% (32/207)\u001b[K\rremote: Counting objects:  16% (34/207)\u001b[K\rremote: Counting objects:  17% (36/207)\u001b[K\rremote: Counting objects:  18% (38/207)\u001b[K\rremote: Counting objects:  19% (40/207)\u001b[K\rremote: Counting objects:  20% (42/207)\u001b[K\rremote: Counting objects:  21% (44/207)\u001b[K\rremote: Counting objects:  22% (46/207)\u001b[K\rremote: Counting objects:  23% (48/207)\u001b[K\rremote: Counting objects:  24% (50/207)\u001b[K\rremote: Counting objects:  25% (52/207)\u001b[K\rremote: Counting objects:  26% (54/207)\u001b[K\rremote: Counting objects:  27% (56/207)\u001b[K\rremote: Counting objects:  28% (58/207)\u001b[K\rremote: Counting objects:  29% (61/207)\u001b[K\rremote: Counting objects:  30% (63/207)\u001b[K\rremote: Counting objects:  31% (65/207)\u001b[K\rremote: Counting objects:  32% (67/207)\u001b[K\rremote: Counting objects:  33% (69/207)\u001b[K\rremote: Counting objects:  34% (71/207)\u001b[K\rremote: Counting objects:  35% (73/207)\u001b[K\rremote: Counting objects:  36% (75/207)\u001b[K\rremote: Counting objects:  37% (77/207)\u001b[K\rremote: Counting objects:  38% (79/207)\u001b[K\rremote: Counting objects:  39% (81/207)\u001b[K\rremote: Counting objects:  40% (83/207)\u001b[K\rremote: Counting objects:  41% (85/207)\u001b[K\rremote: Counting objects:  42% (87/207)\u001b[K\rremote: Counting objects:  43% (90/207)\u001b[K\rremote: Counting objects:  44% (92/207)\u001b[K\rremote: Counting objects:  45% (94/207)\u001b[K\rremote: Counting objects:  46% (96/207)\u001b[K\rremote: Counting objects:  47% (98/207)\u001b[K\rremote: Counting objects:  48% (100/207)\u001b[K\rremote: Counting objects:  49% (102/207)\u001b[K\rremote: Counting objects:  50% (104/207)\u001b[K\rremote: Counting objects:  51% (106/207)\u001b[K\rremote: Counting objects:  52% (108/207)\u001b[K\rremote: Counting objects:  53% (110/207)\u001b[K\rremote: Counting objects:  54% (112/207)\u001b[K\rremote: Counting objects:  55% (114/207)\u001b[K\rremote: Counting objects:  56% (116/207)\u001b[K\rremote: Counting objects:  57% (118/207)\u001b[K\rremote: Counting objects:  58% (121/207)\u001b[K\rremote: Counting objects:  59% (123/207)\u001b[K\rremote: Counting objects:  60% (125/207)\u001b[K\rremote: Counting objects:  61% (127/207)\u001b[K\rremote: Counting objects:  62% (129/207)\u001b[K\rremote: Counting objects:  63% (131/207)\u001b[K\rremote: Counting objects:  64% (133/207)\u001b[K\rremote: Counting objects:  65% (135/207)\u001b[K\rremote: Counting objects:  66% (137/207)\u001b[K\rremote: Counting objects:  67% (139/207)\u001b[K\rremote: Counting objects:  68% (141/207)\u001b[K\rremote: Counting objects:  69% (143/207)\u001b[K\rremote: Counting objects:  70% (145/207)\u001b[K\rremote: Counting objects:  71% (147/207)\u001b[K\rremote: Counting objects:  72% (150/207)\u001b[K\rremote: Counting objects:  73% (152/207)\u001b[K\rremote: Counting objects:  74% (154/207)\u001b[K\rremote: Counting objects:  75% (156/207)\u001b[K\rremote: Counting objects:  76% (158/207)\u001b[K\rremote: Counting objects:  77% (160/207)\u001b[K\rremote: Counting objects:  78% (162/207)\u001b[K\rremote: Counting objects:  79% (164/207)\u001b[K\rremote: Counting objects:  80% (166/207)\u001b[K\rremote: Counting objects:  81% (168/207)\u001b[K\rremote: Counting objects:  82% (170/207)\u001b[K\rremote: Counting objects:  83% (172/207)\u001b[K\rremote: Counting objects:  84% (174/207)\u001b[K\rremote: Counting objects:  85% (176/207)\u001b[K\rremote: Counting objects:  86% (179/207)\u001b[K\rremote: Counting objects:  87% (181/207)\u001b[K\rremote: Counting objects:  88% (183/207)\u001b[K\rremote: Counting objects:  89% (185/207)\u001b[K\rremote: Counting objects:  90% (187/207)\u001b[K\rremote: Counting objects:  91% (189/207)\u001b[K\rremote: Counting objects:  92% (191/207)\u001b[K\rremote: Counting objects:  93% (193/207)\u001b[K\rremote: Counting objects:  94% (195/207)\u001b[K\rremote: Counting objects:  95% (197/207)\u001b[K\rremote: Counting objects:  96% (199/207)\u001b[K\rremote: Counting objects:  97% (201/207)\u001b[K\rremote: Counting objects:  98% (203/207)\u001b[K\rremote: Counting objects:  99% (205/207)\u001b[K\rremote: Counting objects: 100% (207/207)\u001b[K\rremote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 2875 (delta 117), reused 114 (delta 48), pack-reused 2668\u001b[K\n",
            "Receiving objects: 100% (2875/2875), 62.15 MiB | 12.01 MiB/s, done.\n",
            "Resolving deltas: 100% (2001/2001), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYyki82pz8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install sentinelhub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGjZqQl9ox8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install sentinelhub --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6BLfcyto8uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sentinelhub.config --show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TkyDat5qNLK",
        "colab_type": "code",
        "outputId": "0175128b-b1fc-4a45-8eef-e5ca501d3328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!sentinelhub.config --instance_id \"e52da223-f972-43e9-9adc-660887c6a231\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-XclotnqNSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sentinelhub.config --show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8SxQfnoqsTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOI1PXsxr4g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dont run these commands as they change the sentinelhub version\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFwywxngO1JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQwipZB2krfw",
        "colab_type": "code",
        "outputId": "d311df7f-4e68-41a5-a867-2a50a64fef3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# Firstly, some necessary imports\n",
        "\n",
        "# Jupyter notebook related\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "# Built-in modules\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import itertools\n",
        "from enum import Enum\n",
        "\n",
        "# Basics of Python data handling and visualization\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from shapely.geometry import Polygon\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "# Machine learning \n",
        "import lightgbm as lgb\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Imports from eo-learn and sentinelhub-py\n",
        "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
        "    LoadFromDisk, SaveToDisk, EOExecutor\n",
        "from eolearn.io import S2L1CWCSInput\n",
        "from eolearn.io import ExportToTiff\n",
        "from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask\n",
        "from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\n",
        "from eolearn.features import LinearInterpolation, SimpleFilterTask\n",
        "from sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8e4b07010cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Imports from eo-learn and sentinelhub-py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEOTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOPatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearWorkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOverwritePermission\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mLoadFromDisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveToDisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS2L1CWCSInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportToTiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddCloudMaskTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_s2_pixel_cloud_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAddValidDataMaskTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/eolearn/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeopedia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddGeopediaFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlocal_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportToTiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportFromTiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentinelHubInputTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentinelHubDemTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.7.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/eolearn/io/processing_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentinelhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebFeatureService\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMimeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentinelHubDownloadClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSHConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbbox_to_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_time_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentinelhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinelhub_request\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mshr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SentinelHubDownloadClient'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEl61R3lMgmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd sentinelhub-py/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khcaHmUBLcNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Folder where data for running the notebook is stored\n",
        "DATA_FOLDER = os.path.join('..','eo-learn', 'example_data')\n",
        "\n",
        "\n",
        "# Load geojson file\n",
        "country = gpd.read_file(os.path.join(DATA_FOLDER, 'eastern_france.geojson'))\n",
        "\n",
        "# Convert CRS to UTM_33N\n",
        "country_crs = CRS.UTM_33N\n",
        "country = country.to_crs(crs={'init': CRS.ogc_string(country_crs)})\n",
        "\n",
        "# Get the country's shape in polygon format\n",
        "country_shape = country.geometry.values[-1]\n",
        "\n",
        "# Plot country\n",
        "country.plot()\n",
        "plt.axis('off');\n",
        "\n",
        "# Print size \n",
        "print('Dimension of the area is {0:.0f} x {1:.0f} m2'.format(country_shape.bounds[2] - country_shape.bounds[0],\n",
        "                                                             country_shape.bounds[3] - country_shape.bounds[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RfcGzw3LcLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_smaller_patches = True\n",
        "\n",
        "# Create the splitter to obtain a list of bboxes\n",
        "bbox_splitter_large = BBoxSplitter([country_shape], country_crs, (25, 17))\n",
        "bbox_splitter_small = BBoxSplitter([country_shape], country_crs, (25 * 3, 17 * 3))\n",
        "\n",
        "bbox_splitter = bbox_splitter_small if use_smaller_patches else bbox_splitter_large\n",
        "\n",
        "bbox_list = np.array(bbox_splitter.get_bbox_list())\n",
        "info_list = np.array(bbox_splitter.get_info_list())\n",
        "\n",
        "# For the future examples, we will be using a specific set of patches,\n",
        "# but you are free to change the patch ID numbers in the scope of this example\n",
        "# Select a central patch\n",
        "ID = 1549 if use_smaller_patches else 190 \n",
        "\n",
        "# Obtain surrounding patches\n",
        "patchIDs = []\n",
        "for idx, [bbox, info] in enumerate(zip(bbox_list, info_list)):\n",
        "    if (abs(info['index_x'] - info_list[ID]['index_x']) <= 1 and\n",
        "        abs(info['index_y'] - info_list[ID]['index_y']) <= 1):\n",
        "        patchIDs.append(idx)\n",
        "\n",
        "# Check if final size is 3x3\n",
        "if len(patchIDs) != 9:\n",
        "    print('Warning! Use a different central patch ID, this one is on the border.')\n",
        "    \n",
        "# Change the order of the patches (used for plotting later)\n",
        "patchIDs = np.transpose(np.fliplr(np.array(patchIDs).reshape(3, 3))).ravel()\n",
        "    \n",
        "# Prepare info of selected EOPatches\n",
        "geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\n",
        "idxs_x = [info['index_x'] for info in info_list[patchIDs]]\n",
        "idxs_y = [info['index_y'] for info in info_list[patchIDs]]\n",
        "\n",
        "gdf = gpd.GeoDataFrame({'index_x': idxs_x, 'index_y': idxs_y}, \n",
        "                       crs={'init': CRS.ogc_string(country_crs)}, \n",
        "                       geometry=geometry)\n",
        "\n",
        "# save to shapefile\n",
        "shapefile_name = './selected_3x3_bboxes_slovenia_small.shp' if use_smaller_patches \\\n",
        "    else './selected_3x3_bboxes_slovenia_large.shp'\n",
        "gdf.to_file(shapefile_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOczsorQtSOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poly = gdf['geometry'][0]\n",
        "x1, y1, x2, y2 = poly.bounds\n",
        "aspect_ratio = (y1 - y2) / (x1 - x2)\n",
        "\n",
        "# content of the geopandas dataframe\n",
        "gdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVJOKWvftSYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fontdict = {'family': 'monospace', 'weight': 'normal', 'size': 11}\n",
        "\n",
        "# if bboxes have all same size, estimate offset\n",
        "xl, yl, xu, yu = gdf.geometry[0].bounds\n",
        "xoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n",
        "\n",
        "# figure\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "gdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5)\n",
        "country.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5)\n",
        "ax.set_title('Selected 3x3  tiles from Slovenia (25 x 17 grid)');\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5GFUK3ItSfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentinelHubValidData:\n",
        "    \"\"\"\n",
        "    Combine Sen2Cor's classification map with `IS_DATA` to define a `VALID_DATA_SH` mask\n",
        "    The SentinelHub's cloud mask is asumed to be found in eopatch.mask['CLM']\n",
        "    \"\"\"\n",
        "    def __call__(self, eopatch):        \n",
        "        return np.logical_and(eopatch.mask['IS_DATA'].astype(np.bool), \n",
        "                              np.logical_not(eopatch.mask['CLM'].astype(np.bool)))\n",
        "    \n",
        "class CountValid(EOTask):   \n",
        "    \"\"\"\n",
        "    The task counts number of valid observations in time-series and stores the results in the timeless mask.\n",
        "    \"\"\"\n",
        "    def __init__(self, count_what, feature_name):\n",
        "        self.what = count_what\n",
        "        self.name = feature_name\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.name, np.count_nonzero(eopatch.mask[self.what],axis=0))\n",
        "        \n",
        "        return eopatch\n",
        "\n",
        "\n",
        "class NormalizedDifferenceIndex(EOTask):   \n",
        "    \"\"\"\n",
        "    The tasks calculates user defined Normalised Difference Index (NDI) between two bands A and B as:\n",
        "    NDI = (A-B)/(A+B).\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, band_a, band_b):\n",
        "        self.feature_name = feature_name\n",
        "        self.band_a_fetaure_name = band_a.split('/')[0]\n",
        "        self.band_b_fetaure_name = band_b.split('/')[0]\n",
        "        self.band_a_fetaure_idx = int(band_a.split('/')[-1])\n",
        "        self.band_b_fetaure_idx = int(band_b.split('/')[-1])\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        band_a = eopatch.data[self.band_a_fetaure_name][..., self.band_a_fetaure_idx]\n",
        "        band_b = eopatch.data[self.band_b_fetaure_name][..., self.band_b_fetaure_idx]\n",
        "        \n",
        "        ndi = (band_a - band_b) / (band_a  + band_b)\n",
        "        \n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, ndi[..., np.newaxis])\n",
        "        \n",
        "        return eopatch\n",
        "\n",
        "    \n",
        "class EuclideanNorm(EOTask):   \n",
        "    \"\"\"\n",
        "    The tasks calculates Euclidian Norm of all bands within an array:\n",
        "    norm = sqrt(sum_i Bi**2),\n",
        "    where Bi are the individual bands within user-specified feature array.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, in_feature_name):\n",
        "        self.feature_name = feature_name\n",
        "        self.in_feature_name = in_feature_name\n",
        "    \n",
        "    def execute(self, eopatch):\n",
        "        arr = eopatch.data[self.in_feature_name]\n",
        "        norm = np.sqrt(np.sum(arr**2, axis=-1))\n",
        "        \n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, norm[..., np.newaxis])\n",
        "        return eopatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7GQqA33R33C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TASK FOR BAND DATA\n",
        "# add a request for B(B02), G(B03), R(B04), NIR (B08), SWIR1(B11), SWIR2(B12) \n",
        "# from default layer 'ALL_BANDS' at 10m resolution\n",
        "# Here we also do a simple filter of cloudy scenes. A detailed cloud cover \n",
        "# detection is performed in the next step\n",
        "custom_script = 'return [B02, B03, B04, B08, B11, B12];'\n",
        "add_data = S2L1CWCSInput(\n",
        "    layer='BANDS-S2-L1C', \n",
        "    feature=(FeatureType.DATA, 'BANDS'), # save under name 'BANDS'\n",
        "    custom_url_params={CustomUrlParam.EVALSCRIPT: custom_script}, # custom url for 6 specific bands\n",
        "    resx='10m', # resolution x\n",
        "    resy='10m', # resolution y\n",
        "    maxcc=0.8, # maximum allowed cloud cover of original ESA tiles\n",
        ")\n",
        "\n",
        "# TASK FOR CLOUD INFO\n",
        "# cloud detection is performed at 80m resolution \n",
        "# and the resulting cloud probability map and mask \n",
        "# are scaled to EOPatch's resolution\n",
        "cloud_classifier = get_s2_pixel_cloud_detector(average_over=2, dilation_size=1, all_bands=False)\n",
        "add_clm = AddCloudMaskTask(cloud_classifier, 'BANDS-S2CLOUDLESS', cm_size_y='80m', cm_size_x='80m', \n",
        "                           cmask_feature='CLM', # cloud mask name\n",
        "                           cprobs_feature='CLP' # cloud prob. map name\n",
        "                          )\n",
        "\n",
        "# TASKS FOR CALCULATING NEW FEATURES\n",
        "# NDVI: (B08 - B04)/(B08 + B04)\n",
        "# NDWI: (B03 - B08)/(B03 + B08)\n",
        "# NORM: sqrt(B02^2 + B03^2 + B04^2 + B08^2 + B11^2 + B12^2)\n",
        "ndvi = NormalizedDifferenceIndex('NDVI', 'BANDS/3', 'BANDS/2')\n",
        "ndwi = NormalizedDifferenceIndex('NDWI', 'BANDS/1', 'BANDS/3')\n",
        "norm = EuclideanNorm('NORM','BANDS')\n",
        "\n",
        "# TASK FOR VALID MASK\n",
        "# validate pixels using SentinelHub's cloud detection mask and region of acquisition \n",
        "add_sh_valmask = AddValidDataMaskTask(SentinelHubValidData(), \n",
        "                                      'IS_VALID' # name of output mask\n",
        "                                     )\n",
        "\n",
        "# TASK FOR COUNTING VALID PIXELS\n",
        "# count number of valid observations per pixel using valid data mask \n",
        "count_val_sh = CountValid('IS_VALID', # name of existing mask\n",
        "                          'VALID_COUNT' # name of output scalar\n",
        "                         )\n",
        "\n",
        "# TASK FOR SAVING TO OUTPUT (if needed)\n",
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "if not os.path.isdir(path_out):\n",
        "    os.makedirs(path_out)\n",
        "save = SaveToDisk(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAJaVJkDQH74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class LULC(Enum):\n",
        "    NO_DATA            = (0,  'No Data',            'white')\n",
        "    CULTIVATED_LAND    = (1,  'Cultivated Land',    'xkcd:lime')\n",
        "    FOREST             = (2,  'Forest',             'xkcd:darkgreen')\n",
        "    GRASSLAND          = (3,  'Grassland',          'orange')\n",
        "    SHRUBLAND          = (4,  'Shrubland',          'xkcd:tan')\n",
        "    WATER              = (5,  'Water',              'xkcd:azure')\n",
        "    WETLAND            = (6,  'Wetlands',           'xkcd:lightblue')\n",
        "    TUNDRA             = (7,  'Tundra',             'xkcd:lavender')\n",
        "    ARTIFICIAL_SURFACE = (8,  'Artificial Surface', 'crimson')\n",
        "    BARELAND           = (9,  'Bareland',           'xkcd:beige')\n",
        "    SNOW_AND_ICE       = (10, 'Snow and Ice',       'black')\n",
        "    \n",
        "    def __init__(self, val1, val2, val3):\n",
        "        self.id = val1\n",
        "        self.class_name = val2\n",
        "        self.color = val3\n",
        "        \n",
        "# example usecase\n",
        "# LULC.BARELAND.id   # return 9\n",
        "        \n",
        "# Reference colormap things\n",
        "lulc_cmap = mpl.colors.ListedColormap([entry.color for entry in LULC])\n",
        "lulc_norm = mpl.colors.BoundaryNorm(np.arange(-0.5, 11, 1), lulc_cmap.N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIJ3D-LSQIFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name_str = 'small' if use_smaller_patches else 'large'\n",
        "land_cover_path = os.path.join(DATA_FOLDER, 'land_cover_subset_{}'.format(name_str),\n",
        "                               'land_cover_subset_{}.shp'.format(name_str))\n",
        "\n",
        "land_cover_data = gpd.read_file(land_cover_path)\n",
        "\n",
        "rasterization_task = VectorToRaster(land_cover_data, (FeatureType.MASK_TIMELESS, 'LULC'),\n",
        "                                    values_column='lulcid', raster_shape=(FeatureType.MASK, 'IS_VALID'),\n",
        "                                    raster_dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEJ3JjWRQIZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the workflow\n",
        "workflow = LinearWorkflow(\n",
        "    add_data,\n",
        "    add_clm,\n",
        "    ndvi,\n",
        "    ndwi,\n",
        "    norm,\n",
        "    add_sh_valmask,\n",
        "    count_val_sh,\n",
        "    rasterization_task,\n",
        "    save\n",
        ")\n",
        "\n",
        "# Let's visualize it\n",
        "workflow.dependency_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBMymlIwQscq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Execute the workflow\n",
        "time_interval = ['2017-01-01', '2017-12-31'] # time interval for the SH request\n",
        "\n",
        "# define additional parameters of the workflow\n",
        "execution_args = []\n",
        "for idx, bbox in enumerate(bbox_list[patchIDs]):\n",
        "    execution_args.append({\n",
        "        add_data:{'bbox': bbox, 'time_interval': time_interval},\n",
        "        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n",
        "    })\n",
        "    \n",
        "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "executor.run(workers=5, multiprocess=False)\n",
        "\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elddNN3yQsks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EOPatch.load('./eopatches_small/eopatch_0/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXFzqk3eQsp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw the RGB image\n",
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "fig = plt.figure(figsize=(20, 20 * aspect_ratio))\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(np.clip(eopatch.data['BANDS'][0][..., [2, 1, 0]] * 3.5, 0, 1))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7NkEM4_Qsy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['LULC'].squeeze(), cmap=lulc_cmap, norm=lulc_norm)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "cb.set_ticks([entry.id for entry in LULC])\n",
        "cb.ax.set_xticklabels([entry.class_name for entry in LULC], rotation=45, fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LS9d0mHjrMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "vmin, vmax = None, None\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    data = eopatch.mask_timeless['VALID_COUNT'].squeeze()\n",
        "    vmin = np.min(data) if vmin is None else (np.min(data) if np.min(data) < vmin else vmin)\n",
        "    vmax = np.max(data) if vmax is None else (np.max(data) if np.max(data) > vmax else vmax)\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['VALID_COUNT'].squeeze(), vmin=vmin, vmax=vmax, cmap=plt.cm.inferno)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkpLfBiBjrPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "eID = 1\n",
        "eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, eID), lazy_loading=True)\n",
        "\n",
        "ndvi = eopatch.data['NDVI'] # ndvi data cube\n",
        "mask = eopatch.mask['IS_VALID'] # mask of valid pixels\n",
        "time = np.array(eopatch.timestamp) # x axis\n",
        "t, w, h, _ = ndvi.shape \n",
        "\n",
        "ndvi_clean = ndvi.copy()\n",
        "ndvi_clean[~mask] = np.nan # set values of invalid pixels to NaN's\n",
        "\n",
        "# Calculate means, remove NaN's from means\n",
        "ndvi_mean = np.nanmean(ndvi.reshape(t, w * h).squeeze(), axis=1) \n",
        "ndvi_mean_clean = np.nanmean(ndvi_clean.reshape(t, w * h).squeeze(), axis=1)\n",
        "time_clean = time[~np.isnan(ndvi_mean_clean)]\n",
        "ndvi_mean_clean = ndvi_mean_clean[~np.isnan(ndvi_mean_clean)]\n",
        "\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "plt.plot(time_clean, ndvi_mean_clean, 's-', label = 'Mean NDVI with cloud cleaning')\n",
        "plt.plot(time, ndvi_mean, 'o-', label='Mean NDVI without cloud cleaning')\n",
        "plt.xlabel('Time', fontsize=15)\n",
        "plt.ylabel('Mean NDVI over patch', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "\n",
        "plt.legend(loc=2, prop={'size': 15});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMohHcHVjrKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    ndvi = eopatch.data['NDVI']\n",
        "    mask = eopatch.mask['IS_VALID']\n",
        "    ndvi[~mask] = np.nan\n",
        "    ndvi_mean = np.nanmean(ndvi, axis=0).squeeze()\n",
        "    im = ax.imshow(ndvi_mean, vmin=0, vmax=0.8, cmap=plt.get_cmap('YlGn'))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qhUgAcgj486",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    clp = eopatch.data['CLP']\n",
        "    mask = eopatch.mask['IS_VALID']\n",
        "    clp[~mask] = np.nan\n",
        "    clp_mean = np.nanmean(clp, axis=0).squeeze()\n",
        "    im = ax.imshow(clp_mean, vmin=0.0, vmax=0.3, cmap=plt.cm.inferno)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgziXgiAj5Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatenateData(EOTask):\n",
        "    \"\"\" Task to concatenate data arrays along the last dimension\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, feature_names_to_concatenate):\n",
        "        self.feature_name = feature_name\n",
        "        self.feature_names_to_concatenate = feature_names_to_concatenate\n",
        "\n",
        "    def execute(self, eopatch):\n",
        "        arrays = [eopatch.data[name] for name in self.feature_names_to_concatenate]\n",
        "\n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, np.concatenate(arrays, axis=-1))\n",
        "\n",
        "        return eopatch\n",
        "    \n",
        "    \n",
        "class ValidDataFractionPredicate:\n",
        "    \"\"\" Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid, if the \n",
        "    valid data fraction is above the specified threshold.\n",
        "    \"\"\"\n",
        "    def __init__(self, threshold):\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def __call__(self, array):\n",
        "        coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n",
        "        return coverage > self.threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moOukGM0j5EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TASK TO LOAD EXISTING EOPATCHES\n",
        "load = LoadFromDisk(path_out)\n",
        "\n",
        "# TASK FOR CONCATENATION\n",
        "concatenate = ConcatenateData('FEATURES', ['BANDS', 'NDVI', 'NDWI', 'NORM'])\n",
        "\n",
        "# TASK FOR FILTERING OUT TOO CLOUDY SCENES\n",
        "# keep frames with > 80 % valid coverage\n",
        "valid_data_predicate = ValidDataFractionPredicate(0.8)\n",
        "filter_task = SimpleFilterTask((FeatureType.MASK, 'IS_VALID'), valid_data_predicate)\n",
        "\n",
        "# TASK FOR LINEAR INTERPOLATION\n",
        "# linear interpolation of full time-series and date resampling\n",
        "resampled_range = ('2017-01-01', '2017-12-31', 16)\n",
        "linear_interp = LinearInterpolation(\n",
        "    'FEATURES', # name of field to interpolate\n",
        "    mask_feature=(FeatureType.MASK, 'IS_VALID'), # mask to be used in interpolation\n",
        "    copy_features=[(FeatureType.MASK_TIMELESS, 'LULC')], # features to keep\n",
        "    resample_range=resampled_range, # set the resampling range\n",
        "    bounds_error=False # extrapolate with NaN's\n",
        ")\n",
        "\n",
        "# TASK FOR EROSION\n",
        "# erode each class of the reference map\n",
        "erosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LULC','LULC_ERODED'), disk_radius=1)\n",
        "\n",
        "# TASK FOR SPATIAL SAMPLING\n",
        "# Uniformly sample about pixels from patches\n",
        "n_samples = int(4e4) if use_smaller_patches else int(1e5) # no. of pixels to sample\n",
        "ref_labels = list(range(11)) # reference labels to take into account when sampling\n",
        "spatial_sampling = PointSamplingTask(\n",
        "    n_samples=n_samples, \n",
        "    ref_mask_feature='LULC_ERODED', \n",
        "    ref_labels=ref_labels, \n",
        "    sample_features=[  # tag fields to sample\n",
        "        (FeatureType.DATA, 'FEATURES'),\n",
        "        (FeatureType.MASK_TIMELESS, 'LULC_ERODED')\n",
        "    ])\n",
        "\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "if not os.path.isdir(path_out_sampled):\n",
        "    os.makedirs(path_out_sampled)\n",
        "save = SaveToDisk(path_out_sampled, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2WFTX1yj4_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the workflow\n",
        "workflow = LinearWorkflow(\n",
        "    load,\n",
        "    concatenate,\n",
        "    filter_task,\n",
        "    linear_interp,\n",
        "    erosion,\n",
        "    spatial_sampling,\n",
        "    save\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA5i3gYzkHB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%%time\n",
        "   \n",
        "execution_args = []\n",
        "for idx in range(len(patchIDs)):\n",
        "    execution_args.append({\n",
        "        load: {'eopatch_folder': 'eopatch_{}'.format(idx)},\n",
        "        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n",
        "    })\n",
        "    \n",
        "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "executor.run(workers=5, multiprocess=True)\n",
        "\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C7DWleHkHEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load sampled eopatches\n",
        "eopatches = []\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "\n",
        "for i in range(9):\n",
        "    eopatches.append(EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True))    \n",
        "\n",
        "eopatches = np.array(eopatches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S02WeIyIkHHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Definition of the train and test patch IDs\n",
        "train_ID = [0,2,3,4,5,6,7,8] if use_smaller_patches else [0,1,3,4,5,6,7,8]\n",
        "test_ID = [1] if use_smaller_patches else [2]\n",
        "\n",
        "# Set the features and the labels for train and test sets\n",
        "features_train = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
        "labels_train = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
        "features_test = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
        "labels_test = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
        "\n",
        "# get shape\n",
        "p1, t, w, h, f = features_train.shape\n",
        "p2, t, w, h, f = features_test.shape\n",
        "p = p1 + p2\n",
        "\n",
        "# reshape to n x m\n",
        "features_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\n",
        "labels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
        "features_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\n",
        "labels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
        "\n",
        "# remove points with no reference from training (so we dont train to recognize \"no data\")\n",
        "mask_train = labels_train == 0\n",
        "features_train = features_train[~mask_train]\n",
        "labels_train = labels_train[~mask_train]\n",
        "\n",
        "# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\n",
        "mask_test = labels_test == 0\n",
        "features_test = features_test[~mask_test]\n",
        "labels_test = labels_test[~mask_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QisuUczPloIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Set up training classes\n",
        "labels_unique = np.unique(labels_train)\n",
        "\n",
        "# Set up the model\n",
        "model = lgb.LGBMClassifier(\n",
        "    objective='multiclass', \n",
        "    num_class=len(labels_unique), \n",
        "    metric='multi_logloss'\n",
        ")\n",
        "\n",
        "# train the model\n",
        "model.fit(features_train, labels_train)\n",
        "\n",
        "# uncomment to save the model\n",
        "model_base_name = 'model_SI_LULC_smaller' if use_smaller_patches else 'model_SI_LULC_larger'\n",
        "joblib.dump(model, './{}.pkl'.format(model_base_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaIQL5HeloF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment to load the model and replace with your file, usually just correct the date\n",
        "model_path = './model_SI_LULC_smaller.pkl' if use_smaller_patches else './model_SI_LULC_larger.pkl'\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# predict the test labels\n",
        "plabels_test = model.predict(features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdZRajvmloDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test, plabels_test)))\n",
        "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test, plabels_test, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ospmao3MmvXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = np.unique(labels_test)\n",
        "class_names = [entry.class_name for entry in LULC]\n",
        "\n",
        "f1_scores = metrics.f1_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
        "recall = metrics.recall_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
        "precision = metrics.precision_score(labels_test, plabels_test, labels=class_labels, average=None) \n",
        "\n",
        "print('             Class              =  F1  | Recall | Precision')\n",
        "print('         --------------------------------------------------')\n",
        "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
        "    print('         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(lulctype, \n",
        "                                                                         f1_scores[idx] * 100, \n",
        "                                                                         recall[idx] * 100, \n",
        "                                                                         precision[idx] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91qu8CDDmvVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the plotting function\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    np.set_printoptions(precision=2, suppress=True)\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
        "    plt.title(title, fontsize=20)\n",
        "    # plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, fontsize=20)\n",
        "    plt.yticks(tick_marks, classes, fontsize=20)\n",
        "    \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "                 fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(ylabel, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hQ-icKmvTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "conf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\n",
        "plot_confusion_matrix(conf_matrix_gbm, \n",
        "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
        "                      normalize=True, \n",
        "                      ylabel='Truth (LAND COVER)', \n",
        "                      xlabel='Predicted (GBM)',\n",
        "                      title='Confusion matrix');\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "conf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\n",
        "plot_confusion_matrix(conf_matrix_gbm, \n",
        "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
        "                      normalize=True, \n",
        "                      xlabel='Truth (LAND COVER)', \n",
        "                      ylabel='Predicted (GBM)',\n",
        "                      title='Transposed Confusion matrix');\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5JOLgWmvPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 5))\n",
        "\n",
        "label_ids, label_counts = np.unique(labels_train, return_counts=True)\n",
        "\n",
        "plt.bar(range(len(label_ids)), label_counts)\n",
        "plt.xticks(range(len(label_ids)), [class_names[i] for i in label_ids], rotation=45, fontsize=20);\n",
        "plt.yticks(fontsize=20);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqJRhcvmnGb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = np.unique(np.hstack([labels_test, labels_train]))\n",
        "\n",
        "scores_test = model.predict_proba(features_test)\n",
        "labels_binarized = preprocessing.label_binarize(labels_test, classes=class_labels)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for idx,lbl in enumerate(class_labels):\n",
        "    fpr[idx], tpr[idx], _ = metrics.roc_curve(labels_binarized[:, idx], scores_test[:, idx])\n",
        "    roc_auc[idx] = metrics.auc(fpr[idx], tpr[idx])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afwSjvKEnGYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "for idx,lbl in enumerate(class_labels):\n",
        "    if np.isnan(roc_auc[idx]):\n",
        "        continue\n",
        "    plt.plot(fpr[idx], tpr[idx], color=lulc_cmap.colors[lbl],\n",
        "         lw=2, label=class_names[lbl] + ' (%0.5f)' % roc_auc[idx])\n",
        "    \n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 0.99])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title('ROC Curve', fontsize=20)\n",
        "plt.legend(loc=\"center right\", prop={'size': 15})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPsjtyynGVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# names of features\n",
        "fnames = ['B2','B3','B4','B8','B11','B12','NDVI','NDWI','NORM']\n",
        "\n",
        "# get feature importances and reshape them to dates and features\n",
        "z = model.feature_importances_.reshape((t, f))\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax = plt.gca()\n",
        "\n",
        "# plot the importances\n",
        "im = ax.imshow(z, aspect=0.25)\n",
        "plt.xticks(range(len(fnames)), fnames, rotation=45, fontsize=20)\n",
        "plt.yticks(range(t), ['T{}'.format(i) for i in range(t)], fontsize=20)\n",
        "plt.xlabel('Bands and band related features', fontsize=20)\n",
        "plt.ylabel('Time frames', fontsize=20)\n",
        "ax.xaxis.tick_top()\n",
        "ax.xaxis.set_label_position('top') \n",
        "\n",
        "# cax = fig.add_axes([0.82, 0.125, 0.04, 0.755]) \n",
        "# plt.colorbar(im, cax=cax)\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=[ax], orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR8cZR0pnGRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Draw the RGB image\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "fig = plt.figure(figsize=(20, 20 * aspect_ratio))\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(np.clip(eopatch.data['FEATURES'][1][..., [2, 1, 0]] * 2.5, 0, 1))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnqt4FpnVZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b2_t1 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                    1, 3)[..., 1, 0].reshape(p * h * w)\n",
        "b2_t19 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                     1, 3)[..., 19, 0].reshape(p * h * w)\n",
        "ndvi_t1 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                      1, 3)[..., 1, 6].reshape(p * h * w)\n",
        "ndvi_t19 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                       1, 3)[..., 19, 6].reshape(p * h * w)\n",
        "labels = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches]).reshape(p * h * w * 1)\n",
        "\n",
        "# remove nans\n",
        "mask = np.any([np.isnan(b2_t1), np.isnan(b2_t19), np.isnan(ndvi_t1), np.isnan(ndvi_t19), labels==0], axis=0)\n",
        "b2_t1, b2_t19, ndvi_t1, ndvi_t19, labels = [array[~mask] for array in [b2_t1, b2_t19, ndvi_t1, ndvi_t19, labels]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntkHWSprnVXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "plot_labels = np.unique(labels)\n",
        "plot_colors = lulc_cmap.colors\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.hist([b2_t1[labels == i] for i in np.unique(labels)], 100, (0.1, 0.7),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('B2', fontsize=20)\n",
        "plt.title('Optimal time', fontsize=20)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.hist([b2_t19[labels == i] for i in np.unique(labels)],100,(0.1, 0.7),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('B2', fontsize=20);\n",
        "plt.title('Non-optimal time', fontsize=20)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist([ndvi_t1[labels == i] for i in plot_labels],100,(-0.4, 0.8),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels],\n",
        "         label=[class_names[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('NDVI', fontsize=20)\n",
        "plt.legend(loc=1, prop={'size': 15})\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.hist([ndvi_t19[labels == i] for i in np.unique(labels)],100,(-0.4, 0.8),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('NDVI', fontsize=20);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHNVBY_cnVTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictPatch(EOTask):\n",
        "    \"\"\"\n",
        "    Task to make model predictions on a patch. Provide the model and the feature, \n",
        "    and the output names of labels and scores (optional)\n",
        "    \"\"\"\n",
        "    def __init__(self, model, features_feature, predicted_labels_name, predicted_scores_name=None):\n",
        "        self.model = model\n",
        "        self.features_feature = features_feature\n",
        "        self.predicted_labels_name = predicted_labels_name\n",
        "        self.predicted_scores_name = predicted_scores_name\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        ftrs = eopatch[self.features_feature[0]][self.features_feature[1]]\n",
        "        \n",
        "        t, w, h, f = ftrs.shape\n",
        "        ftrs = np.moveaxis(ftrs, 0, 2).reshape(w * h, t * f)\n",
        "        \n",
        "        plabels = self.model.predict(ftrs)\n",
        "        plabels = plabels.reshape(w, h)\n",
        "        plabels = plabels[..., np.newaxis]\n",
        "        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.predicted_labels_name, plabels)\n",
        "        \n",
        "        if self.predicted_scores_name:\n",
        "            pscores = self.model.predict_proba(ftrs)\n",
        "            _, d = pscores.shape\n",
        "            pscores = pscores.reshape(w, h, d)\n",
        "            eopatch.add_feature(FeatureType.DATA_TIMELESS, self.predicted_scores_name, pscores)\n",
        "        \n",
        "        return eopatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugG2C261ntDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK TO LOAD EXISTING EOPATCHES\n",
        "load = LoadFromDisk(path_out_sampled)\n",
        "\n",
        "# TASK FOR PREDICTION\n",
        "predict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\n",
        "\n",
        "# TASK FOR SAVING\n",
        "save = SaveToDisk(str(path_out_sampled), overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
        "\n",
        "# TASK TO EXPORT TIFF\n",
        "export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LBL_GBM'))\n",
        "tiff_location = './predicted_tiff'\n",
        "if not os.path.isdir(tiff_location):\n",
        "    os.makedirs(tiff_location)\n",
        "\n",
        "workflow = LinearWorkflow(\n",
        "    load,\n",
        "    predict,\n",
        "    export_tiff,\n",
        "    save\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1NOU3uMntAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of execution arguments for each patch\n",
        "execution_args = []\n",
        "for i in range(len(patchIDs)):\n",
        "    execution_args.append(\n",
        "        {\n",
        "            load: {'eopatch_folder': 'eopatch_{}'.format(i)},\n",
        "            export_tiff: {'filename': '{}/prediction_eopatch_{}.tiff'.format(tiff_location, i)},\n",
        "            save: {'eopatch_folder': 'eopatch_{}'.format(i)}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# run the executor on 2 cores\n",
        "executor = EOExecutor(workflow, execution_args)\n",
        "\n",
        "# uncomment below save the logs in the current directory and produce a report!\n",
        "#executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "\n",
        "executor.run(workers=2, multiprocess=False)\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJdIxr4zns8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# merge with gdal_merge.py (with compression) using bash command magic\n",
        "!gdal_merge.py -o predicted_tiff/merged_prediction.tiff -co compress=LZW predicted_tiff/prediction_eopatch_*\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09E6hs0uoSdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze(), cmap=lulc_cmap, norm=lulc_norm)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "cb.set_ticks([entry.id for entry in LULC])\n",
        "cb.ax.set_xticklabels([entry.class_name for entry in LULC], rotation=45, fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC_mw9hUoSbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Draw the Reference map\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "idx = np.random.choice(range(9))\n",
        "inspect_size = 100\n",
        "\n",
        "eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, idx), lazy_loading=True)\n",
        "\n",
        "w, h = eopatch.mask_timeless['LULC'].squeeze().shape\n",
        "\n",
        "w_min = np.random.choice(range(w - inspect_size))\n",
        "h_min = np.random.choice(range(h - inspect_size))\n",
        "\n",
        "ax = plt.subplot(2, 2, 1)\n",
        "plt.imshow(eopatch.mask_timeless['LULC'].squeeze()[w_min: w_min + inspect_size, h_min : h_min + inspect_size],\n",
        "           cmap=lulc_cmap, norm=lulc_norm)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Ground Truth', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 2)\n",
        "plt.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze()[w_min: w_min + inspect_size, h_min: h_min + inspect_size],\n",
        "           cmap=lulc_cmap, norm=lulc_norm)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Prediction', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 3)\n",
        "mask = eopatch.mask_timeless['LBL_GBM'].squeeze() != eopatch.mask_timeless['LULC'].squeeze()\n",
        "plt.imshow(mask[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([]);\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Difference', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 4)\n",
        "image = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\n",
        "plt.imshow(image[w_min: w_min + inspect_size, h_min: h_min + inspect_size])\n",
        "plt.xticks([])\n",
        "plt.yticks([]);\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('True Color', fontsize=20)\n",
        "\n",
        "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_MHdpOuoSYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrTZkof5oSTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}